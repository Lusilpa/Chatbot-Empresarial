#Biblioteca Pandas para analise de dados
import pandas as pd

#Consulta em uma base de dados (DataSets)
import csv

#Biblioteca para tratamento de string
import string

#Biblioteca para Processamento de Linguagem natural
#Baixando os recursos necess√°rios do NLTK
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('punkt_tab')

#Biblioteca para remover a acentua√ß√£o
from unidecode import unidecode

#Vetoriza√ß√£o e similaridade
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

#Interface Grafica - biblioteca Streamlit e configura√ß√£o
import streamlit as st

st.set_page_config(page_title="ITEMM Chatbot", page_icon="ü§ñ")
st.title("ü§ñ Assistente Emprensarial")


#Carregando o DataSet e realizando o pr√©-processamento e vetoriza√ß√£o

@st.cache_resource
def carregar_dados():
    # Carregando o DataSet
    df = pd.read_csv(r'C:\Users\luanp\OneDrive\Documentos\ITEMM\dataset.csv', 
                      delimiter=';', 
                      quoting=csv.QUOTE_MINIMAL)
    
    # Pr√©-processamento da base
    df["Pergunta_Preprocessada"] = df["Pergunta"].apply(preprocessamento)
    
    # Vetoriza√ß√£o
    vec = TfidfVectorizer()
    matrix = vec.fit_transform(df["Pergunta_Preprocessada"])
    return df, vec, matrix

# Fun√ß√£o para remover pontua√ß√£o
def remove_pontuacao(text):
    texto_limpo = ''
    for palavra in text:
      if palavra not in string.punctuation:
        texto_limpo += palavra
    return texto_limpo

# Fun√ß√£o de pr√©-processamento do texto (remo√ß√£o de pontua√ß√£o, acentua√ß√£o, stopwords e tokeniza√ß√£o)
def preprocessamento(texto):
    texto = remove_pontuacao(texto)
    texto = unidecode(texto)
    texto = texto.lower()
    tokens = word_tokenize(texto)
    stop_words = stopwords.words('portuguese')
    tokens = [token for token in tokens if token not in stop_words]
    return ' '.join(tokens)

# Inicializa os dados e o modelo
dataset, vectorizer, tfidf_matrix = carregar_dados()

def obter_resposta(pergunta):
    pergunta_processada = preprocessamento(pergunta)
    pergunta_vector = vectorizer.transform([pergunta_processada])
    similaridades = cosine_similarity(pergunta_vector, tfidf_matrix)
    pergunta_index = similaridades.argmax()
    
    # Threshold de seguran√ßa: se a similaridade for muito baixa, avisa o usu√°rio
    if similaridades[0][pergunta_index] < 0.2:
        return "Desculpe, n√£o encontrei uma teoria espec√≠fica para essa d√∫vida no meu banco de dados."
    
    return dataset["Resposta"].iloc[pergunta_index]

# Inicializa o hist√≥rico de mensagens na sess√£o
if "messages" not in st.session_state:
    st.session_state.messages = []

# Exibe mensagens anteriores do hist√≥rico
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Campo de entrada
if question := st.chat_input("Pergunte sobre Taylor, Fayol, Mayo..."):
    
    # Adiciona e exibe a pergunta do usu√°rio
    st.session_state.messages.append({"role": "user", "content": question})
    with st.chat_message("user"):
        st.markdown(question)

    # L√≥gica de sa√≠da
    flags = ['Fechar', 'Sair', 'Tchau']
    if any(f.lower() in question.lower() for f in flags):
        answer = "Finalizando Chat. At√© logo!"
    else:
        # Gera a resposta
        answer = obter_resposta(question)

        # Exibe e salva a resposta do assistente
    with st.chat_message("assistant"):
        st.markdown(answer)

    st.session_state.messages.append({"role": "assistant", "content": answer})